---
title: 'Mint a Genome NFT'
description: DeepMind recently released a new type of Transformer called the Perceiver IO, which was able to achieve state of the art accuracy across multiple data types (text, images, point clouds, and more). In this episode of the AlphaCare series, I'll explain how Perceiver works, and how we used it to improve accuracy scores for Cardiac video data. The EchoNet dataset was recently made public by Stanford University, and it contains 10K privatized heart videos from patients. We'll also discuss why Transformer networks work so well, and how by using 2 key features (Cross attention & positional embeddings), the Perceiver improved on all variants of Transformers. Get hype!
publishedDate: 2021-09-22T17:49:44.101Z
lastModifiedDate: 2021-09-22T17:49:44.101Z
coverImage: ''
authors:
    - sirajRaval
modules:
    - source: index
lessons:
    - source: intro
videoId: XOCuQAKhsMw
---
